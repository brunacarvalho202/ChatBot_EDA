# ü§ñ Chatbot de An√°lise de Dados com LLM e Integra√ß√£o em Cloud

## üìò Descri√ß√£o / Objetivo

O foco deste projeto √© o desenvolvimento de uma **intelig√™ncia artificial para an√°lise explorat√≥ria de dados na nuvem**, utilizando **modelos de linguagem (LLMs)** para interpretar perguntas feitas em linguagem natural e traduzi-las em opera√ß√µes de an√°lise sobre um dataset real.



### Principais objetivos do desafio:

1. **Criar um chatbot inteligente** que utilize um modelo de linguagem (LLM) para auxiliar usu√°rios em tarefas de **an√°lise explorat√≥ria de dados (EDA)**.  
2. Permitir que o usu√°rio envie **consultas em linguagem natural**, e o chatbot seja capaz de interpret√°-las corretamente.  
3. Fazer com que o chatbot **traduza essas consultas** em opera√ß√µes SQL/Pandas apropriadas sobre uma **base de dados hospedada em cloud**
4. Retornar **insights significativos e visualiza√ß√µes** a partir dos resultados obtidos, de forma clara e interativa.  




---
## üè∑Ô∏è Evid√™ncias, com prints e v√≠deo, de como o chatbot est√° reagindo at√© esse ponto da implementa√ß√£o:
---

LINK DO VIDEO DE DEMONSTRA√á√ÉO: [https://youtu.be/Z6yg7dRSofI?si=WbTZh6PVjBSFX0BC]  <br>


![WhatsApp Image 2025-10-06 at 12 55 35](https://github.com/user-attachments/assets/fda60630-1858-42fa-9c9e-27189b2a18bd)

![WhatsApp Image 2025-10-06 at 14 32 50](https://github.com/user-attachments/assets/f03371bd-b241-40e9-b2e7-888df49e65fc)

![WhatsApp Image 2025-10-06 at 14 35 18](https://github.com/user-attachments/assets/6095bc36-4ea0-4d74-9a64-19d6048bd55e)


## üìä Observa√ß√£o sobre o Dataset usado

O dataset original cont√©m cerca de **150 colunas**, relacionadas ao **contexto de concess√£o de cr√©dito** e perfil financeiro de indiv√≠duos.  
No entanto, para o escopo deste desafio, o chatbot foi projetado para trabalhar apenas com as seguintes colunas relevantes:

| Coluna     | Descri√ß√£o                                                                 |
|-------------|---------------------------------------------------------------------------|
| `REF_DATE`  | Data de refer√™ncia do registro                                            |
| `TARGET`    | Alvo bin√°rio de inadimpl√™ncia (1 = Mau pagador, atraso > 60 dias em 2 meses) |
| `VAR2`      | Sexo do indiv√≠duo                                                         |
| `IDADE`     | Idade do indiv√≠duo                                                        |
| `VAR4`      | Flag de √≥bito (indica se o indiv√≠duo faleceu)                             |
| `VAR5`      | Unidade Federativa (UF) brasileira                                        |
| `VAR8`      | Classe social estimada                                                    |

üî∏ O dataset foi convertido do formato **CSV** para **Parquet**, visando maior efici√™ncia de leitura e compress√£o.  
üî∏ A vers√£o final est√° **armazenada em um bucket S3 da AWS**, acessada diretamente pela aplica√ß√£o.



---

## üß© Tecnologias utilizadas e seus motivos de escolha diante do cen√°rio do desafio

- **Python 3.10+**
- **Streamlit** ‚Äî Interface de chatbot e visualiza√ß√£o (Simplicidade e rapidez para desenvolvimento)
- **LangChain** ‚Äî Orquestra√ß√£o de ferramentas e racioc√≠nio do LLM (Traz uma abstra√ß√£o da l√≥gica complexa para ser implementada entre os componentes usados)
- **DuckDB** ‚Äî Engine SQL local integrada √† cloud (Aplica a query SQL diretamente no parquet que est√° armazenado na aws s3 e foi fortemente recomendado)
- **AWS S3 e boto3** ‚Äî Armazenamento de dados em Parquet (J√° tinha usado uma vez para estudo e foi mais familiar, considerando os cr√©ditos dispon√≠veis e rapidez na implementa√ß√£o)
- **Pandas / Matplotlib / Seaborn / Plotly** ‚Äî Manipula√ß√£o e visualiza√ß√£o de dados (Apesar de usar SQL, a entrada dos usu√°rio pode ser melhor respondida em certos cen√°rios com outras bibliotecas do python)
- **Google Vertex AI (ChatVertexAI)** ‚Äî Modelos de linguagem (LLM) (O cr√©dito liberado para uso foi maior em rela√ß√£o aos outros testados que tiveram problema no teste -openai e dois modelos do hugging face-)
- **Python-dotenv** ‚Äî Carregamento de vari√°veis de ambiente (Por seguran√ßa guardar as credenciais dos servi√ßos necess√°rios na l√≥gica)
- **LLM usado no Vertex: gemini-2.0-flash-001**


---


## üß† Arquitetura

Durante o desenvolvimento do desafio, foi usado um quadro no drawio onde registrei todo meu fluxo de pensamento e diagramas (percorrer ele pois √© um mapa mental): [https://drive.google.com/file/d/11ktLvDx5ljq2JsvZM34S9gztqkTtwF0Y/view?usp=sharing]

<img width="8377" height="8822" alt="flow" src="https://github.com/user-attachments/assets/3927efc6-689a-47ea-99c6-236b6d3e2d1c" />


- **Frontend:** Chatbot interativo desenvolvido em **Streamlit**, capaz de receber perguntas em linguagem natural e exibir respostas em texto, tabelas e gr√°ficos.  
- **Orquestra√ß√£o / Backend:** **LangChain** coordena as chains que transformam consultas do usu√°rio em queries SQL, c√≥digo Pandas e insights textuais.  
- **LLM:** **Google Vertex AI (ChatVertexAI)** interpreta as perguntas, gera queries e insights.  
- **Database Engine:** **DuckDB** executa consultas r√°pidas sobre os dados em formato Parquet, armazenados na nuvem.  
- **Cloud Storage:** **AWS S3** armazena os datasets em formato Parquet para acesso eficiente. (o csv tambem foi armazenado por )
- **Visualiza√ß√£o e an√°lise:** **Pandas**, **Matplotlib**, **Seaborn** e **Plotly** processam e exibem dados de forma interativa e est√°tica.
  

---

## üöß Desafios enfrentados

- Dificuldades em lidar com credenciais em cloud (AWS, GCP, etc.)
- Problemas com os LLM (openai n√£o tinha mais quota, dois modelos do hugging face n√£o permitiam e etc)
- Problemas com as vari√°veis de ambiente (Tinha que ficar manipulando no terminal a declara√ß√£o e verifica√ß√£o delas por que dava erro 403 entre tempos - precisava entender melhor o funcionamento do dotenv -)
- Estudo em pouco tempo das principais ferramentas usadas (LangChain e DuckDB -ainda n√£o tinha usado essas ferramentas-)
- Em lidar com as ferramentas novas, junto com o prazo e querer melhorar o script de ETL aplicado (Precisei priorizar e planejar pr√≥ximos passos constatemente a medida que dificuldades ou erros apareciam)
- Cria√ß√£o dos mocks para as classes de teste unit√°rios e n√£o ficar usando as chamadas reais do s3 e LLM

---

## üîÆ Pr√≥ximas melhorias

- Mudar a abordagem sequencial para dinamica que usei com langchain (Percebi depois de estudar que usei uma forma sequencial do langchain com as chains e poderia ser mais dinamico com o aente decidindo a tool [])
- Melhorar a contextualiza√ß√£o do LLM para evitar erros de interpreta√ß√£o  
- Adicionar suporte a gr√°ficos (N√£o consegui fazer rodar ainda essa tool, est√° em an√°lise -  as tools de gr√°fico existem e foram testadas mas n√£o foram encaixadas no fluxo sequencial das chains)
- Implementar cache local de resultados
- Melhorar o script de limpeza e transforma√ß√£o nos dados (tem colunas que est√£o retornando com valores nulos quando n√£o deveria, como idade por exemplo)
- Pesquisar uma forma mais otimizada de fazer as consultas (seja com outra tecnologia como Athena ou outra extens√£o diferente do parquet)
- Refatorar os testes unit√°rios para ter uma melhor cobertura do projeto (ajustar os mocks e acrescentar testes unit√°rios para cada tool)
- Aperfei√ßoar os prompts e docs strings usadas para ter um melhor uso da LLM
- Analisar, debugar e refatorar a estrutura da chain para a orquestra√ß√£o ocorrer de uma melhor forma

---

---
## ‚öôÔ∏è Como usar o projeto

**Resumo inicial:** as intru√ß√µes s√£o para rodar em localhost com o dockerfile disponivel, mas para rodar por completo esse projeto voc√™ precisa gerar suas credenciais pessoais dos servi√ßos externos usados, como o llm e o aws s3. 

a documenta√ß√£o da langchain para uso dos modelos vertex que usei pode ajudar: [https://share.google/nRPyHueEGS6eqQUeI]

- **[PASSO 1]** Clonar o reposit√≥rio:

comando: ```git clone https://github.com/brunacarvalho202/ChatBot_EDA.git```

- **[PASSO 2]** Criar suas credenciais para os servi√ßos usados como os usados: aws s3 e modelo de llm gemini-2.0-flash-001 <br>
- **[PASSO 3]** Criar arquivos sens√≠veis que s√£o usados mas n√£o foram expostos como .env e config.py

  **observa√ß√£o 1: abaixo est√£o as variaveis de ambiente usadas para voce usar as mesmas se nao quiser adaptar seu projeto**


```env
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_REGION=
S3_BUCKET=
S3_KEY=
S3_DATASET_PATH=
S3_PARQUET_PATH=
GOOGLE_APPLICATION_CREDENTIALS=
```


  **observa√ß√£o 2: abaixo um modelo do arquivo config.py para voc√™ usar se precisar**

```python
import os
AWS_ACCESS_KEY_ID = os.getenv("AWS_ACCESS_KEY_ID")
AWS_SECRET_ACCESS_KEY = os.getenv("AWS_SECRET_ACCESS_KEY")
AWS_REGION = os.getenv("AWS_REGION")
S3_BUCKET = os.getenv("S3_BUCKET")
S3_KEY = os.getenv("S3_KEY")
S3_DATASET_PATH = os.getenv("S3_DATASET_PATH")
S3_PARQUET_PATH = os.getenv("S3_PARQUET_PATH")
GOOGLE_APPLICATION_CREDENTIALS = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
PROJECT_ID = "<SEU_PROJECT_ID_DO_GOOGLE>"
CREDENTIALS = GOOGLE_APPLICATION_CREDENTIALS
 ```


- **[PASSO 4]** Rodar o container Docker com o comando que est√° dentro dele (Substitua /caminho/local/ pelos caminhos corretos no seu computador)
- **[PASSO 5]** Acessar o chatbot localmente: **http://localhost:8501**


---

## üß† Pontos levados em considera√ß√£o durante o desenvolvimento: 

**(N√£o est√£o em ordem de prioridade, apenas por organiza√ß√£o)** <br>
**(Mesmo que tenham sido atendidos em uma certa porcentagem, s√£o levados em considera√ß√£o para as pr√≥ximas refatora√ß√µes**


**1. ESCALABILIDADE (decis√µes de design que permitam escalar o chatbot para conjuntos de dados maiores ou consultas mais complexas)** <br>
**2. EXTENSIBILIDADE: Estrutura clara que facilite a adi√ß√£o de novos recursos ou integra√ß√£o com outras fontes de dados**<br>


- O csv foi original foi armazenado na cloud para que caso haja necessidade de retornar a ele, j√° esta disponivel de ser acessado via servi√ßos s3.
- O parquet foi gerado a partir do csv apenas com as colunas necess√°rias requisitadas para otimizar a consulta e j√° teve um script de limpeza e conversao de dados aplicado nele.
- O script de convers√£o csv -> parquet foi colocado na pasta de scripts para que caso queira mudar a l√≥gica de ETL aplicada mexa apenas no script de ETL e/ou 
  caso precise gerar um novo parquet com outras especifica√ß√µes sejam feitas apenas adapta√ß√µes como o nome do parquet que vai ser gerado
- O duckdb √© apenas uma forma de aplicar a query, ent√£o caso venha ser refatorado para usar outra ferramenta, foi implementada um interface gen√©rica que s√≥ precisa implementar o m√©todo de execute dela e passar a usar ele (al√©m de n√£o precisa apagar o do duckdb)
- Nas consultas, foi pensado para o SQL ser executado sempre primeiro mesmo que o escolhido de ser usado para que retorne apenas a opr√ß√£o de dados que vai ser usada para as ferramentas posteriores


**3. INTERFACE DO CHATBOT: uma interface simples e intuitiva para interagir** <br>
**4. RESPOSTAS NATURAIS: deve responder em linguagem natural, explicando insihts de forma clara e concisa**<br>


- O chatbot foi pensado para ter a cara de chat comum onDe traz familiaridade e facilidade de uso. 
- Usa uma divis√£o entre a resposta do chat e a entrada do usu√°rio apra as mensagens n√£o fiquem perdidas.
- Tem apenas um campo de entrada e bot√£o de enviar para atender ao objetivo principal dessa primeira vers√£o
- os gr√°ficos retornados tem p√ß√£o de aumentar a visualiza√ß√£o, pesquisar ou baixar ele
- O chatbot retorna um resumo textual do que foi mostrado em tabela


**5. ENTENDIMENTO DAS CONSULTAS: O chat deve interpretar corretamente consultas dos usuarios incluindo filtros, agrega√ß√µes e analise de tendencias** <br>
**6. PRECIS√ÉO DAS RESPOSTAS: devem ser precisas e derivadas do conjunto de dados armazenado na cloud**<br>
**7. IMPLEMENTA√á√ÉO T√âCNICA: integra√ß√£o com LLM, integra√ß√£o com a Cloud, garantir consulas e recupera√ß√£o de dados eficientes**<br>

- O fluxo conta com o uso de prompts estruturados para que cada vez mais as respostas sejam o padr√£o esperado e diminua os erros
- As consultas sql s√£o instru√≠das a sempre virem com o caminho do arquivo do arquivo da cloud
- A escolha do langchain, al√©m da abstra√ß√£o e facilidade, foi para ter um controle maior da orquestra√ß√£o das ferramentas a serem usadas na l√≥gica, al√©m da flexibilidade de refatorar esse fluxo


**8. QUALIDADE DO C√ìDIGO: limpo, legivel, bem documentado**<br>
**9. TESTES: testes unit√°rios para garantir a confiabilidade do c√≥digo**<br>

- Pelo fato de a maioria das ferramentas terem sido o primeiro contato, o c√≥digo ainda est√° com muito coment√°rio para facilitar o estudo e documenta√ß√£o
- Os testes unit√°rios visaram cobrir o m√°xima das configura√ß√µes necess√°rias como conex√µes com os servi√ßos



